{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import picos\n",
    "import numpy as np\n",
    "import itertools\n",
    "import sympy as sym\n",
    "from sympy.physics.quantum import TensorProduct, Dagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what follows we define input and output values and we define a basis for the algebraic operations that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_VALUES  = [[0,1],[0,1],[0,1]]\n",
    "INPUT_VALUES = [[0,1,2],[0,1],[0,1]]\n",
    "NR_PARTIES = len(OUTPUT_VALUES)\n",
    "\n",
    "def test_party_nr():\n",
    "    assert len(INPUT_VALUES) == NR_PARTIES\n",
    "\n",
    "def norm_pure_state(state):\n",
    "    # [0] in the output because it outputs a 1x1 matrix annoyingly\n",
    "    return sym.sqrt((Dagger(state)*state)[0]) \n",
    "\n",
    "def projector_onto_state(state):\n",
    "    normm = norm_pure_state(state)\n",
    "    if normm != 0:    \n",
    "        return state*Dagger(state)/(normm**2)  # |psi><psi|/<psi|psi>\n",
    "    else:\n",
    "        print(\"ERROR: norm 0\")\n",
    "        return 0\n",
    "    \n",
    "sig0   = sym.Matrix([[1, 0],[0, 1]])\n",
    "# All these are written in the Z basis, |0>, |1>\n",
    "sig1   = sym.Matrix([[0, 1],[1, 0]]) \n",
    "sig2   = sym.Matrix([[0,-sym.I],[sym.I, 0]])\n",
    "sig3   = sym.Matrix([[1, 0],[0,-1]])\n",
    "\n",
    "def ret_proj_eigs(obs):\n",
    "    obs_vec, obs_val = obs.diagonalize()\n",
    "    ret = []\n",
    "    for i in range(obs_vec.shape[1]):\n",
    "        ret.append(projector_onto_state(obs_vec[:,i]))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alice\n",
    "A0 = sig3 #sig_z\n",
    "A1 = sig1 #sig_x\n",
    "A2 = sig2 #sig_y\n",
    "\n",
    "A_obs = [A0,A1,A2]\n",
    "A_proj = []\n",
    "for i in range(len(INPUT_VALUES[0])):\n",
    "    A_proj.append(ret_proj_eigs(A_obs[i]))\n",
    "\n",
    "\n",
    "#Bob\n",
    "phi = np.arctan(1/np.sqrt(2))\n",
    "B0 = np.cos(phi) * sig1 + np.sin(phi) * sig2\n",
    "B1 = np.cos(phi) * sig1 - np.sin(phi) * sig2\n",
    "\n",
    "B_obs = [B0,B1]\n",
    "B_proj = []\n",
    "for i in range(len(INPUT_VALUES[1])):\n",
    "    B_proj.append(ret_proj_eigs(B_obs[i]))\n",
    "\n",
    "\n",
    "#Charie\n",
    "C0 = sig3\n",
    "C1 = sig1\n",
    "\n",
    "C_obs = [C0,C1]\n",
    "C_proj = []\n",
    "for i in range(len(INPUT_VALUES[2])):\n",
    "    C_proj.append(ret_proj_eigs(C_obs[i]))\n",
    "\n",
    "P_proj = [A_proj,B_proj,C_proj]\n",
    "\n",
    "#U\n",
    "e1 = sym.Matrix([1,0])\n",
    "e2 = sym.Matrix([0,1])\n",
    "\n",
    "\n",
    "\n",
    "Phi_minus = 1/np.sqrt(2) * (TensorProduct(e1,e1)-TensorProduct(e2,e2))\n",
    "Psi_plus  = 1/np.sqrt(2) * (TensorProduct(e1,e2)+TensorProduct(e2,e1))\n",
    "Phi_plus  = 1/np.sqrt(2) * (TensorProduct(e1,e1)+TensorProduct(e2,e2))\n",
    "\n",
    "ALPHA = sym.symbols(\"alpha\")\n",
    "ini_state = Phi_plus * Dagger(Phi_plus)\n",
    "ini_state = (ALPHA) * ini_state + (1-ALPHA) * 1.0/4 * TensorProduct(sig0,sig0)\n",
    "\n",
    "alpha = np.pi/8\n",
    "psi0 =  np.sin(alpha) * Phi_minus + np.cos(alpha) * Psi_plus\n",
    "psi1 = -np.cos(alpha) * Phi_minus + np.sin(alpha) * Psi_plus\n",
    "\n",
    "# A and B+C share Phi_plus. This U acts on B+C's part. If the box measures 0,\n",
    "# then it gives psi0 to Bob and Charlie to measure; if the box measures 1, it \n",
    "# gives psi1 to B+c.\n",
    "U = psi0 * Dagger(e1) + psi1 * Dagger(e2)\n",
    "\n",
    "# Now I will get the final state for all three parties.\n",
    "\n",
    "Big_U = TensorProduct(sig0,U)\n",
    "final_state = Big_U * ini_state * Dagger(Big_U)\n",
    "\n",
    "\n",
    "def meas_proj(party,i,o):\n",
    "    return P_proj[party][i][o]\n",
    "\n",
    "def probability(rho, inputs, outputs):\n",
    "    kronn = meas_proj(0,inputs[0],outputs[0])\n",
    "    for i in np.arange(1,NR_PARTIES):\n",
    "        kronn = TensorProduct(kronn,meas_proj(i,inputs[i],outputs[i]))\n",
    "    ret = sym.simplify(sym.trace(rho*kronn))\n",
    "    return sym.nsimplify(ret,tolerance=1e-10,rational=False).evalf()\n",
    "\n",
    "def test_probability():\n",
    "    for x,y,z in itertools.product(*INPUT_VALUES):\n",
    "        suma = 0\n",
    "        for a,b,c in itertools.product(*OUTPUT_VALUES):\n",
    "            suma = suma + probability(final_state*Dagger(final_state),\n",
    "                                      [x,y,z],\n",
    "                                      [a,b,c])\n",
    "        assert (suma - 1) < 1e-10\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining our probability distribtuion, we define the LP problem in PICOS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_det_points = 8\n",
    "det = [[[0 for a in range(len(OUTPUT_VALUES[0]))]\n",
    "             for x in range(len(INPUT_VALUES[0]))]\n",
    "                for i in range(nr_det_points)]\n",
    "\n",
    "counter = 0\n",
    "for a_tuple in itertools.product(OUTPUT_VALUES[0],repeat=len(INPUT_VALUES[0])):\n",
    "    a_list = list(a_tuple)\n",
    "    for x in INPUT_VALUES[0]:\n",
    "        det[counter][x][a_tuple[x]] = 1\n",
    "    counter = counter + 1\n",
    "\n",
    "P = picos.Problem()\n",
    "\n",
    "q = picos.RealVariable(\"q\",nr_det_points*2*2*2*2)\n",
    "\n",
    "alpha = picos.RealVariable(\"alpha\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we add the constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.add_constraint(alpha >= 0)\n",
    "P.add_constraint(alpha <= 1)\n",
    "\n",
    "q_vars = [[[[[0 for c in range(len(OUTPUT_VALUES[2]))]\n",
    "                for b in range(len(OUTPUT_VALUES[1]))]\n",
    "                    for z in range(len(INPUT_VALUES[2]))]\n",
    "                        for y in range(len(INPUT_VALUES[1]))]\n",
    "                            for lam in range(nr_det_points)]\n",
    "i=0\n",
    "for lam in range(nr_det_points):\n",
    "    for y in range(len(INPUT_VALUES[1])):\n",
    "        for z in range(len(INPUT_VALUES[2])):\n",
    "            for b in range(len(OUTPUT_VALUES[1])):\n",
    "                for c in range(len(OUTPUT_VALUES[2])):         \n",
    "                    q_vars[lam][y][z][b][c] = q[i]\n",
    "                    i = i + 1\n",
    "    \n",
    "for a,b,c in itertools.product(*OUTPUT_VALUES):\n",
    "    for x,y,z in itertools.product(*INPUT_VALUES):\n",
    "        suma = 0\n",
    "        for i in range(nr_det_points):\n",
    "            suma = suma + det[i][x][a] * q_vars[i][y][z][b][c]\n",
    "        prob1 = probability(final_state,[x,y,z],[a,b,c])\n",
    "        # change symbolic ALPHA to PICOS variable alpha\n",
    "        prob2 = (sym.lambdify(ALPHA,prob1))(alpha)\n",
    "        P.add_constraint(suma == prob2)\n",
    "        \n",
    "# non signaling for bob: sum over C, make this not depent on C's input\n",
    "for lam in range(nr_det_points):\n",
    "    for b,y in itertools.product(OUTPUT_VALUES[1],INPUT_VALUES[1]):\n",
    "        for z1,z2 in itertools.combinations(INPUT_VALUES[2],2):\n",
    "            #combinations('ABCD', 2) --> AB AC AD BC BD CD\n",
    "            #we use combinations becausee for no signalling we want for every pair \n",
    "            #of different y1's to show that they are different, but y1_1 = y1_2\n",
    "            #is the same as y1_2 = y1_1, so we use combinations instead of iter.product\n",
    "            #to avoid adding the same equality twice, or redundant equalities\n",
    "            #such as y1_1 = y1_1.\n",
    "            \n",
    "            # we calculate the two marginals for bob by summing over charlie\n",
    "            suma_z1 = 0\n",
    "            for c in OUTPUT_VALUES[2]:\n",
    "                suma_z1 = suma_z1 + q_vars[lam][y][z1][b][c]\n",
    "            suma_z2 = 0\n",
    "            for c in OUTPUT_VALUES[2]:\n",
    "                suma_z2 = suma_z2 + q_vars[lam][y][z2][b][c]\n",
    "                \n",
    "            P.add_constraint(suma_z1 == suma_z2)  \n",
    "\n",
    "# non signaling for charlie: sum over B, make this not depent on B's input\n",
    "for lam in range(nr_det_points):\n",
    "    for c,z in itertools.product(OUTPUT_VALUES[2],INPUT_VALUES[2]):\n",
    "        for y1,y2 in itertools.combinations(INPUT_VALUES[1],2):\n",
    "            suma_y1 = 0\n",
    "            for b in OUTPUT_VALUES[1]:\n",
    "                suma_y1 = suma_y1 + q_vars[lam][y1][z][b][c]\n",
    "            suma_y2 = 0\n",
    "            for b in OUTPUT_VALUES[1]:\n",
    "                suma_y2 = suma_y2 + q_vars[lam][y2][z][b][c]\n",
    "                \n",
    "            P.add_constraint(suma_y1 == suma_y2)  \n",
    "\n",
    "# marginal charlie\n",
    "\n",
    "P.add_constraint(q >= 0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we solve the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem status: feasible\n",
      "Noise tolerance: alpha= 0.577350269189626\n"
     ]
    }
   ],
   "source": [
    "P.set_objective(\"max\",alpha)\n",
    "#P.set_objective(None)\n",
    "\n",
    "\n",
    "solution = P.solve(solver=\"mosek\")\n",
    "print(\"Problem status:\",solution.problemStatus)\n",
    "\n",
    "print(\"Noise tolerance: alpha=\", alpha.value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "correlator = ( -2*TensorProduct(A2,B0,sig0)+2*TensorProduct(A2,B1,sig0)\n",
    "              + TensorProduct(A0,B0,C0) + TensorProduct(A0,B1,C1)\n",
    "              + TensorProduct(A1,B1,C1) - TensorProduct(A1,B0,C0)\n",
    "              + TensorProduct(A0,B0,C1) + TensorProduct(A0,B1,C0)\n",
    "              + TensorProduct(A1,B0,C1) - TensorProduct(A1,B1,C0) )\n",
    "\n",
    "def corr_noise_resistance(state,correlator,noise=1):\n",
    "    return sym.nsimplify(sym.trace(state*correlator),\n",
    "                tolerance=1e-10,rational=False).evalf().subs(ALPHA,noise)\n",
    "    \n",
    "\n",
    "P_d = P.dual\n",
    "\n",
    "P_d.solve(solver=\"mosek\")\n",
    "##%%\n",
    "#len(P_d.variables)\n",
    "#P.variables\n",
    "#len(P.constraints)\n",
    "#print(P_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
